# Corrective RAG (CRAG)

## VisÃ£o Geral

O **CRAG** (Corrective Retrieval Augmented Generation) Ã© uma evoluÃ§Ã£o do modelo **RAG** (Retrieval-Augmented Generation).  
Enquanto o RAG se baseia diretamente em documentos recuperados, o CRAG adiciona uma camada de â€œautocorreÃ§Ã£oâ€, capaz de avaliar a confiabilidade desses documentos antes de usÃ¡-los na geraÃ§Ã£o de texto.  
Assim, o CRAG reduz o risco de alucinaÃ§Ãµes em Grandes Modelos de Linguagem (LLMs), jÃ¡ que filtra informaÃ§Ãµes enganosas ou fora de contexto, algo que o RAG nÃ£o faz de forma explÃ­cita.

## MotivaÃ§Ã£o

Modelos de linguagem tendem a cometer erros factuais quando se baseiam em informaÃ§Ãµes insuficientes ou incorretas, o que chamamos de **alucinaÃ§Ãµes**.  
O RAG tenta corrigir isso anexando documentos relevantes ao prompt do modelo. PorÃ©m, se a recuperaÃ§Ã£o falha, o modelo pode se basear em conteÃºdo irrelevante, agravando o problema.  
O CRAG resolve esse ponto fraco ao verificar a precisÃ£o dos documentos recuperados e, se necessÃ¡rio, busca informaÃ§Ãµes adicionais (por exemplo, via pesquisa na web).

## Principais DiferenÃ§as para o RAG

- **AvaliaÃ§Ã£o de Documentos**:  
  No RAG, o conteÃºdo retornado pelo sistema de recuperaÃ§Ã£o geralmente Ã© inserido sem qualquer triagem;  
  JÃ¡ no CRAG hÃ¡ um _retrieval evaluator_ que pontua a relevÃ¢ncia de cada documento.

- **AÃ§Ãµes Baseadas em Confiabilidade**:

  - **Correct**: usa o que foi recuperado, mas ainda passa por uma filtragem interna para destacar apenas trechos relevantes.
  - **Incorrect**: descarta a recuperaÃ§Ã£o inicial e faz buscas externas (web), ampliando a base de conhecimento.
  - **Ambiguous**: mescla informaÃ§Ãµes internas e externas, mantendo maior flexibilidade quando nÃ£o hÃ¡ certeza absoluta sobre a qualidade dos trechos iniciais.

- **Refinamento de Conhecimento**:  
  Em vez de usar todo o documento (que pode ter parÃ¡grafos irrelevantes), o CRAG faz uma decomposiÃ§Ã£o em blocos, filtra o que nÃ£o serve e recompÃµe apenas o essencial.

- **Uso de Buscas Externas**:  
  Quando julga que nenhum documento interno Ã© confiÃ¡vel, o CRAG consulta fontes adicionais online, escapando da limitaÃ§Ã£o de um corpus fixo.

## Mecanismo de AutocorreÃ§Ã£o

O CRAG introduz um mÃ³dulo de avaliaÃ§Ã£o (por exemplo, **GPT-4o-mini**) que determina se o documento recuperado faz sentido para a consulta do usuÃ¡rio.  
Diferentemente de depender sÃ³ de um grande modelo, esse mÃ³dulo rÃ¡pido e leve possibilita checar vÃ¡rias fontes sem custo computacional exagerado.  
Ao filtrar documentos incorretos ou incompletos, aumenta a seguranÃ§a do sistema antes de chegar ao modelo gerador principal.

## Vantagens

- **Menos AlucinaÃ§Ã£o**:  
  O CRAG detecta e ignora conteÃºdo que nÃ£o se relaciona ao tema da pergunta, reduzindo erros factuais.

- **Maior Flexibilidade**:  
  Decide dinamicamente entre confiar no corpus local ou buscar na web, adaptando-se conforme o tipo de consulta.

- **Plug-and-Play**:  
  Pode ser acoplado em diversos pipelines de geraÃ§Ã£o, pois nÃ£o exige que o modelo gerador seja re-treinado para avaliar documentos.

- **Robustez**:  
  Em situaÃ§Ãµes em que o sistema de recuperaÃ§Ã£o falha, o CRAG nÃ£o â€œdesisteâ€, mas aciona buscas adicionais para garantir que a resposta seja baseada em dados confiÃ¡veis.

## ConclusÃ£o

O CRAG Ã© um aprimoramento do RAG, oferecendo um filtro de correÃ§Ã£o que protege o processo de geraÃ§Ã£o contra informaÃ§Ãµes imprecisas.  
Ao avaliar a qualidade dos documentos e alternar entre dados internos e buscas externas, o CRAG mitiga o risco de alucinaÃ§Ã£o e melhora a exatidÃ£o das respostas.  
Seu enfoque na reutilizaÃ§Ã£o de blocos relevantes e no descarte de partes irrelevantes torna o sistema mais confiÃ¡vel e centrado no que realmente importa para a pergunta feita.

No artigo aqui, sÃ£o realizadas algumas etapas:

1. Se pelo menos um documento exceder o limite de relevÃ¢ncia, entÃ£o prossegue para a geraÃ§Ã£o.
2. Antes da geraÃ§Ã£o, realiza o refinamento do conhecimento:
   - Divide o documento em "faixas de conhecimento".
   - Avalia cada faixa e filtra as irrelevantes.
3. Se todos os documentos ficarem abaixo do limite de relevÃ¢ncia ou se o avaliador estiver em dÃºvida, o framework busca uma fonte de dados adicional:
   - UtilizarÃ¡ busca na web para complementar a recuperaÃ§Ã£o.

## ImplementaÃ§Ã£o (LangGraph)

Vamos implementar algumas dessas ideias do zero usando **LangGraph**:

- Vamos pular a fase de _refinamento do conhecimento_ como primeira abordagem. Isso pode ser adicionado posteriormente como um nÃ³, se desejado.
- Se quaisquer documentos forem irrelevantes, vamos optar por complementar a recuperaÃ§Ã£o com busca na web.
- Usaremos **Tavily Search** para busca na web.
- Vamos usar **reescrita de consulta** para otimizar a busca na web.

Aqui estÃ¡ um documento detalhado em Markdown que explica os conceitos e o funcionamento completo do seu projeto, que usa RAG (Retrieval-Augmented Generation) com um agente baseado em um grafo de execuÃ§Ã£o (Graph / LangGraph):

---

# ğŸ“š Projeto: Sistema de Perguntas e Respostas com RAG e Graph Agent

## SumÃ¡rio

- [ğŸ“– VisÃ£o Geral](#ğŸ“–-visÃ£o-geral)
- [ğŸ“‚ Estrutura do Projeto](#ğŸ“‚-estrutura-do-projeto)
- [ğŸ› ï¸ Componentes e Funcionamento](#ğŸ› ï¸-componentes-e-funcionamento)

  - [1ï¸âƒ£ Repository](#1ï¸âƒ£-repository)
  - [2ï¸âƒ£ RelevantDocument](#2ï¸âƒ£-relevantdocument)
  - [3ï¸âƒ£ Agent](#3ï¸âƒ£-agent)

- [âš™ï¸ Workflow do Agente (Graph)](#âš™ï¸-workflow-do-agente-graph)
- [ğŸš€ Fluxo Completo de ExecuÃ§Ã£o](#ğŸš€-fluxo-completo-de-execuÃ§Ã£o)
- [ğŸ“Œ Tecnologias Utilizadas](#ğŸ“Œ-tecnologias-utilizadas)
- [ğŸ“š Conceitos de RAG e Graph](#ğŸ“š-conceitos-de-rag-e-graph)

---

## ğŸ“– VisÃ£o Geral

Este projeto implementa um sistema de Resposta a Perguntas (QA - Question Answering) que combina RAG (Retrieval-Augmented Generation) com um agente programÃ¡vel em grafo usando **LangGraph**.

O sistema Ã© capaz de:

âœ… Recuperar documentos de uma base vetorial
âœ… Avaliar se os documentos sÃ£o relevantes Ã  pergunta
âœ… Reformular a pergunta se necessÃ¡rio
âœ… Fazer busca na web como fallback
âœ… Gerar uma resposta final com base no contexto

---

## ğŸ“‚ Estrutura do Projeto

```bash
.
â”œâ”€â”€ main.py
â”œâ”€â”€ agent.py
â”œâ”€â”€ repository.py
â”œâ”€â”€ relevant_document.py
â””â”€â”€ .env
```

---

## ğŸ› ï¸ Componentes e Funcionamento

### 1ï¸âƒ£ `Repository`

Arquivo: `repository.py`

ResponsÃ¡vel por:

âœ… Carregar URLs (posts do blog)
âœ… Fazer _Web Scraping_ com `WebBaseLoader`
âœ… Dividir o texto em chunks com `RecursiveCharacterTextSplitter`
âœ… Gerar embeddings com `OpenAIEmbeddings`
âœ… Salvar os embeddings em um banco vetorial com `ChromaDB`

```python
vectorstore = Chroma.from_documents(
    documents=doc_splits,
    collection_name="rag-chroma",
    embedding=OpenAIEmbeddings(),
    persist_directory="./chroma_db"
)
```

Retorna: um `retriever` que permite buscar documentos relevantes a uma pergunta.

---

### 2ï¸âƒ£ `RelevantDocument`

Arquivo: `relevant_document.py`

ResponsÃ¡vel por:

âœ… Classificar a relevÃ¢ncia de documentos com um _grader_ binÃ¡rio (sim/nÃ£o)
âœ… Gerar a resposta final com base nos documentos
âœ… Reescrever a pergunta caso necessÃ¡rio

Componentes:

#### a) `GradeDocuments` (LLM Grader)

Modelo Pydantic que define um output esperado com score `"sim"` ou `"nÃ£o"`.

#### b) `relevant()`

- Recupera documentos do retriever
- Avalia a relevÃ¢ncia com um LLM (modelo `"gpt-4.1-nano"`)

#### c) `generate()`

- Utiliza um prompt RAG (`rlm/rag-prompt`)
- Invoca o modelo para gerar a resposta com base nos documentos

#### d) `question_rewriter()`

- Reescreve perguntas para melhorar a busca
- Exemplo: converte "Chain of Hindsight" para algo mais descritivo

---

### 3ï¸âƒ£ `Agent`

Arquivo: `agent.py`

ResponsÃ¡vel por:

âœ… Definir o workflow de execuÃ§Ã£o em forma de grafo (LangGraph)
âœ… Controlar o fluxo entre as etapas:

- RecuperaÃ§Ã£o de documentos
- AvaliaÃ§Ã£o de relevÃ¢ncia
- ReformulaÃ§Ã£o da pergunta
- Busca na Web
- GeraÃ§Ã£o final de resposta

#### `GraphState`

Define o estado que Ã© passado entre os nÃ³s do grafo:

```python
class GraphState(TypedDict):
    question: str
    generation: str
    web_search: str
    documents: List[str]
```

---

## âš™ï¸ Workflow do Agente (Graph)

```mermaid
graph TD
    A[START] --> B[Recuperar documentos]
    B --> C[Avaliar documentos]
    C -->|Relevantes| E[Gerar resposta]
    C -->|NÃ£o relevantes| D[Reformular pergunta]
    D --> F[Busca Web]
    F --> E
    E --> G[END]
```

---

## ğŸš€ Fluxo Completo de ExecuÃ§Ã£o

Arquivo: `main.py`

1ï¸âƒ£ Cria o repositÃ³rio e indexa os documentos
2ï¸âƒ£ Cria o componente de avaliaÃ§Ã£o e geraÃ§Ã£o
3ï¸âƒ£ Cria o agente com as etapas definidas no grafo
4ï¸âƒ£ Roda o grafo com uma pergunta inicial

```python
agent = Agent(retriever, rag_chain, retrieval_grader, question_rewriter)
app = agent.create_workflow()
agent.run(app)
```

Exemplo de pergunta:

```python
"Quais sÃ£o os tipos de memÃ³ria de agentes?"
```

---

## ğŸ“Œ Tecnologias Utilizadas

- `LangChain`
- `LangGraph`
- `ChromaDB`
- `OpenAIEmbeddings`
- `ChatOpenAI`
- `TavilySearchResults` (busca Web)
- `.env` para variÃ¡veis de ambiente

---

## ğŸ“š Conceitos de RAG e Graph

### âœ¨ RAG - Retrieval-Augmented Generation

EstratÃ©gia que **combina LLMs com uma base de conhecimento**:

- Em vez de depender 100% do LLM, recupera documentos relevantes
- Usa os documentos como "contexto" para gerar uma resposta mais factual
- Mitiga alucinaÃ§Ãµes do LLM

### ğŸ”„ Graph (LangGraph)

Representa o fluxo de execuÃ§Ã£o de um agente como um **grafo de estados**:

- Cada nÃ³ executa uma etapa (ex: recuperar, avaliar, gerar)
- CondiÃ§Ãµes definem os caminhos (ex: "documentos nÃ£o relevantes â†’ reformular pergunta")
- Permite controle fino e transparÃªncia no processo
